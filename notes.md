
# Section 1 Introduction
## 5

我们要做的其实是让机器他有自己学习的能力，也就我们要做的应该machine learning的方向。讲的比较拟人化一点，所谓machine learning的方向，就是你就写段程序，然后让机器人变得了很聪明，他就能够有学习的能力。接下来，你就像教一个婴儿、教一个小孩一样的教他，你并不是写程序让他做到这件事，你是写程序让它具有学习的能力。然后接下来，你就可以用像教小孩的方式告诉它。假设你要叫他学会做语音识别，你就告诉它这段声音是“Hi”，这段声音就是“How are you”，这段声音是“Good bye”。希望接下来它就学会了，你给它一个新的声音，它就可以帮你产生语音识别的结果。

## 6

如果你希望他学会怎么做图像识别，你可能不太需要改太多的程序。因为他本身就有这种学习的能力，你只是需要交换下告诉它：看到这张图片，你要说这是猴子；看到这张图片，然后说是猫；看到这张图片，可以说是狗。它具有图像识别的能力，接下来看到它之前没有看过的猫，希望它可以认识。

## 7

如果讲的更务实一点的话，machine learning所做的事情，你可以想成就是在寻找一个function，要让机器具有一个能力，这种能力是根据你提供给他的资料，它去寻找出我们要寻找的function。还有很多关键问题都可以想成是我们就是需要一个function。

在语音识别这个问题里面，我们要找一个function，它的输入是声音讯号，他的输出是语音识别的文字。这个function非常非常的复杂，有人会想说我来用一些写规则的方式，读很多语言学文献，然后写一堆规则，然后做语音识别。这件事情，60年代就有人做，但到现在都还没有做出来。语音识别太过复杂，这个function太过的复杂，不是人类所可以写出来，这是可以想象的。所以我们需要凭借的机器的力量，帮我们把这个function找出来。

假设你要做图像识别，那就是找一个function，输入一张图片，然后输出图片里面有什么样的东西。
或者是大家都一直在说的Alpha GO，如果你要做一个可以下围棋machine时，其实你需要的也就是找一个function。这个function的输入是围棋上十九* 十九的棋盘。告诉机器在十九* 十九的棋盘上，哪些位置有黑子，哪些位置有白子。然后机器就会告诉你，接下来下一步应该落子在哪。或者是你要做一个聊天机器人，那你需要的是一个function，这个function的输入就是使用者的input，它的输出就是机器的回应。

## 8

以下我先很简短的跟大家说明怎么样找出这个function，找出function的framework是什么呢？我们以图像识别为例，我们找个function输入一张图片，它告诉我们这个图片里面有什么样的东西。

在做这件事时，你的起手事是你要先准备一个function set(集合)，这个function里面有成千上万的function。举例来说，这个function在里面,有一个f1，你给它看一只猫，它就告诉你输出猫，看一只狗就输出狗。有一个function f2它很怪，你给它看猫，它说是猴子；你给他看狗，它说是蛇。你要准备一个function set，这个function set里面有成千上万的function。这件事情讲起来可能有点抽象，你可能会怀疑说怎么会有成千上万的function，我怎么把成千上万的function收集起来，这个内容我们之后会再讲。

总之，我们先假设你手上有一个function set，这个function set就叫做model(模型)。

## 9

有了这个function set，接下来机器要做的事情是：它有一些训练的资料，这些训练资料告诉机器说一个好的function，它的输入输出应该长什么样子，有什么样关系。你告诉机器说呢，现在在这个图像识别的问题里面，如果看到这个猴子，看到这个猴子图也要输出猴子，看到这个猫的图也要输出猴子猫，看到这个狗的图，就要输出猴子猫狗，这样才是对的。只有这些训练资料，你拿出一个function，机器就可以判断说，这个function是好的还是不好的。

机器可以根据训练资料判断一个function是好的，还是不好的。举例来说：在这个例子里面显然$f_1$，他比较符合training data的叙述，比较符合我们的知识。所以f1看起来是比较好的。$f_2$看起来是一个荒谬的function。我们今天讲的这个task叫做supervised learning。

## 10

如果你告诉机器input和output这就叫做supervised learning，之后我们也会讲到其他不同的学习场景。现在机器有办法决定一个function的好坏。但光能够决定一个function的好坏是不够的，因为在你的function set里面，他有成千上万的function，它有会无穷无尽的function，所以我们需要一个有效率的演算法，有效率的演算法可以从function的set里面挑出最好的function。一个一个衡量function的好坏太花时间，实际上做不到。所以我们需要有一个好的演算法，从function set里面挑出一个最好的的function，这个最好的function将它记为$f^*$

找到$f^ *$之后，我们希望用它应用到一些场景中，比如：图像识别，输入一张在机器没有看过的猫，然后希望输出也是猫。你可能会说：机器在学习时没有看到这只猫，那咋样知道在测试时找到的最好function $f^ *$可以正确识别这只猫呢？这就是machine learning里面非常重要的问题：机器有举一反三的能力，这个内容后面再讲。

左边这个部分叫training，就是学习的过程；右边这个部分叫做testing，学好以后你就可以拿它做应用。所以在整个machine learning framework整个过程分成了三个步骤。第一个步骤就是找一个function，第二个步骤让machine可以衡量一个function是好还是不好，第三个步骤是让machine有一个自动的方法，有一个好演算法可以挑出最好的function。

## 11

机器学习其实只有三个步骤，这三个步骤简化了整个process。可以类比为：把大象放进冰箱。我们把大象塞进冰箱，其实也是三个步骤：把门打开；象塞进去；后把门关起来，然后就结束了。所以说，机器学习三个步骤，就好像是说把大象放进冰箱，也只需要三个步骤。


##  12-13

如图为这是Learning Map，看起来是有点复杂的，我们一块一块来解释，接下里我们将从图的左上角来进行学习。

## 14

Regression是一种machine learning的task，当我们说：我们要做regression时的意思是，machine找到的function，它的输出是一个scalar，这个叫做regression。举例来说，在作业一里面，我们会要你做PM2.5的预测（比如说预测明天上午的PM2.5） ，也就是说你要找一个function，这个function的输出是未来某一个时间PM2.5的一个数值，这个是一个regression的问题。

机器要判断function明天上午的PM2.5输出，你要提供给它一些资讯，它才能够猜出明天上午的PM2.5。你给他资讯可能是今天上的PM2.5、昨天上午的PM2.5等等。这是一个function，它吃我们给它过去PM2.5的资料，它输出的是预测未来的PM2.5。

若你要训练这种machine，如同我们在Framework中讲的，你要准备一些训练资料，什么样的训练资料？你就告诉它是今天我们根据过去从政府的open data上搜集下来的资料。九月一号上午的PM2.5是63，九月二号上午的PM2.5是65，九月三号上午的PM2.5是100。所以一个好的function输入九月一号、九月二号的PM2.5，它应该输出九月三号的PM2.5；若给function九月十二号的PM2.5、九月十三号的PM2.5，它应该输出九月十四号的PM2.5。若收集更多的data，那你就可以做一个气象预报的系统。

## 15-16

接下来讲的是Classification（分类）的问题。Regression和Classification的差别就是我们要机器输出的东西的类型是不一样。在Regression中机器输出的是一个数值，在Classification里面机器输出的是类别。假设Classification问题分成两种，一种叫做二分类输出的是是或否（Yes or No）；另一类叫做多分类（Multi-class），在Multi-class中是让机器做一个选择题，等于是给他数个选项，每个选项都是一个类别，让他从数个类别里选择正确的类别。

## 17

举例来说，二分类可以鉴别垃圾邮件，将其放到垃圾箱。那怎么做到这件事呢？其实就是需要一个function，它的输入是一个邮件，输出为邮件是否为垃圾邮件。

你要训练这样的function很简单，给他一大堆的Data并告诉它，现在输入这封邮件，你应该说是垃圾邮件，输入这封邮件，应该说它不是垃圾邮件。你给他够多的这种资料去学，它就可以自动找出一个可以侦测垃圾邮件的function。

## 18

多分类的举一个文章分类的例子，现在网络上有非常非非常多的新闻，也许没有人会把所有的新闻看完，但希望机器自动帮一把新闻做分类。怎么做呢？你需要的是一个function，它的输入是一则新闻，输出是新闻属于哪个类别，你要做的事情就是解这个选择题。

若要训练这种机器就要准备很多训练资料（Training Data），然后给它新的文章，新闻它能给你正确的结果。

## 19

刚才讲的都是让machine去解的任务，接下来要讲的是在解任务的过程中第一步就是要选择function set，选不同的function set就是选不同的model。Model有很多种，最简单的就是线性模型，但我们会花很多时间在非线性的模型上。在非线性的模型中最耳熟能详的就是Deep learning。

## 20

在做Deep learning时，它的function是特别复杂的，所以它可以做特别复杂的事情。比如它可以做图像识别，这个复杂的function可以描述pixel和class之间的关系。

## 21

用Deep learning的技术也可以让机器下围棋，
下围棋这个task 其实就是一个分类的问题。对分类问题我们需要一个很复杂的function，输入是一个棋盘的格子，输出就是下一步应该落子的位置。我们知道一个棋盘上有十九乘十九的位置可以落子，所以今天下围棋这件事情，你就可以把它想成是一个十九乘十九个类别的分类问题，或者是你可以把它想成是一个有十九乘十九个选项的选择题。


你要怎么训练机器让他学会下围棋呢？你要搜集训练资料，告诉机器现在这个function输入输出分别应该是什么。就看到某样的盘式，我们应该输出什么样结果。

怎么收集资料呢？你可以从人类过去下的棋库里面搜集。举例来说，你收集了柯洁和李世石下的那一盘棋的棋谱。李世石出手先下五之5，柯洁次手下天元，李世石第三手下五之5。

## 22

所以若你有了这样的棋谱之后，可以告诉machine如果现在有人落子下5之五，下一步就落子在天元；若五之五和天元都有落子，那就要落子在另外一个五之5上。然后你给它足够多的棋谱，他就学会下围棋了。

## 23

刚才我们讲的都是supervised learning（监督学习），监督学习的问题是我们需要大量的training data。training data告诉我们要找的function的input和output之间的关系。如果我们在监督学习下进行学习，我们需要告诉机器function的input和output是什么。这个output往往没有办法用很自然的方式取得，需要人工的力量把它标注出来，这些function的output叫做label。

那有没有办法减少label需要的量呢？就是半监督学习。

## 24

假设你先想让机器鉴别猫狗的不同。你想做一个分类器让它告诉你，图片上是猫还是狗。你有少量的猫和狗的labelled data，但是同时你又有大量的Unlabeled data，但是你没有力气去告诉机器说哪些是猫哪些是狗。在半监督学习的技术中，这些没有label的data，他可能也是对学习有帮助。这个我们之后会讲为什么这些没有label的data对学习会有帮助。


## 25

另外一个减少data用量的方向是迁移学习。

## 26

迁移学习的意思是：假设我们要做猫和狗的分类问题，我们也一样，只有少量的有label的data。但是我们现在有大量的data，这些大量的data中可能有label也可能没有label。但是他跟我们现在要考虑的问题是没有什么特别的关系的，我们要分辨的是猫和狗的不同，但是这边有一大堆其他动物的图片还是动画图片（凉宫春日，御坂美琴）你有这一大堆不相干的图片，它到底可以带来什么帮助。这个就是迁移学习要讲的问题。


## 27

更加进阶的就是无监督学习，我们希望机器可以学到无师自通。

## 28

如果在完全没有任何label的情况下，到底机器可以学到什么样的事情。举例来说，如果我们给机器看大量的文章（在去网络上收集站文章很容易，网络上随便爬就可以）让机器看过大量的文章以后，它到底可以学到什么事情。

## 29

它能不能够学会每一个词汇的意思，要让机器学会每一个词汇的意思，你可以想成是我们找一个function，然后你把一个词汇丢进去。比如说你把“apple”丢进这个function里面，机器要输出告诉你说这个词会是什么意思。也许他用一个向量来表示这个词汇的各种不同的特性。但现在讲是无监督学习的问题，你现在只有一大堆的文章，也就是说你只有词汇，你只有function的输入，没有任何的输出。那你到底要怎么解决这个问题。

## 30

我们举另外一个无监督学习的例子：假设我们今天带机器去动物园让它看一大堆的动物，它能不能够在看了一大堆动物以后，它就学会自己创造一些动物。那这个都是真实例子。仔细看了大量的动物以后，它就可以自己的画一些狗出来。有眼睛长在身上的狗、还有乳牛狗等等。

## 31

这个Task也是一个无监督学习的问题，这个function的输入不知道是什么，可能是某一个code代表要输出图片的特性，输出是一张图片。你给机器看到的只有非常大量的图片，只有function的input，没有output。机器要咋样生成新的图片，这是我们后面要解决的问题。


## 32

在machine要解的任务上我们讲了Regression、classification，还有一类的问题是structured learning。

## 33

structured learning 中让机器输出的是要有结构性的，举例来说：在语音识别里面，机器输入是声音讯号，输出是一个句子。句子是要很多词汇拼凑完成。它是一个有结构性的object。或者是说在机器翻译里面你说一句话，你输入中文希望机器翻成英文，它的输出也是有结构性的。或者你今天要做的是人脸识别，来给机器看张图片，它会知道说最左边是长门，中间是凉宫春日，右边是宝玖瑠。然后机器要把这些东西标出来，这也是一个structure learning问题。 

## 34

 其实多数人可能都听过regression，也听过classification，你可能不见得听过structure learning。很多教科书都直接说，machine learning是两大类的问题，regression，和classification。machine learning只有regression和classification两类问题，就好像告诉你：我们所熟知的世界只有五大洲，但是这只是真实世界的一小部分，真正的世界是如图所示。
 
真正世界还应该包括structure learning，这里面还有很多问题是没有探究的。

## 35

最后一部分就是reinforcement learning的问题。

## 36

reinforcement learning其实是一个已经发展了很久的技术，但近期受到大家的关注是因为data mining将reinforcement learning技术用来玩一些小游戏。另外一个就是Alpha Go。

## 37

我们若将强化学习和监督学习进行比较时，在监督学习中我们会告诉机器正确答案是什么。若现在我们要用监督学习的方法来训练一个聊天机器人，你的训练方式会是：你就告诉机器，现在使用者说了hello，你就说hi，现在使用者说了byebye ，你就说good bye。所以机器有一个人当他家教在他旁边手把手的教他每件事情，这就是监督学习。

reinforcement learning是什么呢？在reinforcement learning里面，我们没有告诉机器正确的答案是什么，机器所拥有的只有一个分数，就是他做的好还是不好。若我们现在要用reinforcement learning方法来训练一个聊天机器人的话，他训练的方法会是这样：你就把机器发到线下，让他的和面进来的客人对话，然后想了半天以后呢，最后仍旧勃然大怒把电话挂掉了。那机器就学到一件事情就是刚才做错了。但是他不知道哪边错了，它就要回去自己想道理，是一开始就不应该打招呼吗？还是中间不应该在骂脏话了之类。它不知道，也没有人告诉它哪里做的不好，它要回去反省检讨哪一步做的不好。机器要在reinforcement learning的情况下学习，机器是非常intelligence的。 reinforcement learning也是比较符合我们人类真正的学习的情景，这是你在学校里面的学习老师会告诉你答案，但在真实社会中没人回告诉你正确答案。你只知道你做得好还是做得不好，如果机器可以做到reinforcement learning，那确实是比较intelligence。

## 38

若我们用Alpha Go当做例子时，supervised learning就是告诉机器：看到这个盘式你就下“5-5”，看到这个盘式你就下“3-3”

reinforcement learning的意思是：机器跟对手互下，机器会不断的下棋，最后赢了，机器就会知道下的不错，但是究竟是哪里可以使它赢，它其实是不知道的。我们知道Alpha Go其实是用监督学习加上reinforcement learning去学习的。先用棋谱做监督学习，然后在做reinforcement learning，但是reinforcement learning需要一个对手，如果使用人当对手就会很让费时间，所以机器的对手是另外一个机器。

## 39

大家注意一下这个不同的方块，我是用不同的颜色来表示。同样的颜色不同的方块是同一个类型的，这边的蓝色的方块，指的是学习的情景，通常学习的情景是你没有办法控制的。比如，因为我们没有data做监督学习，所以我们才做reinforcement learning。
红色的是指你的task，你要解的问题，你要解的这个问题随着你用的方程的不同，有regression、有classification、有structured。所以在不同的情境下，都有可能要解这个task。最后，在这些不同task里面有不同的model，用绿色的方块表示。


# Section 2 Linear Regression

## 42

Regression 就是找到一个函数 $function$ ，通过输入特征 $x$，输出一个数值 $Scalar$。
应用举例
- 股市预测（Stock market forecast）
	- 输入：过去10年股票的变动、新闻咨询、公司并购咨询等
	- 输出：预测股市明天的平均值
- 自动驾驶（Self-driving Car）
	- 输入：无人车上的各个sensor的数据，例如路况、测出的车距等
	- 输出：方向盘的角度
- 商品推荐（Recommendation）
    - 输入：商品A的特性，商品B的特性
    - 输出：购买商品B的可能性

## 43
- Pokemon精灵攻击力预测（Combat Power of a pokemon）：
	- 输入：进化前的CP值、物种（Bulbasaur）、血量（HP）、重量（Weight）、高度（Height）
	- 输出：进化后的CP值

## 44 
模型步骤
- step1：模型假设，选择模型框架（线性模型）
- step2：模型评估，如何判断众多模型的好坏（损失函数）
- step3：模型优化，如何筛选最优的模型（梯度下降）


### Step 1：模型假设 - 线性模型
#### 一元线性模型（单个特征）

以一个特征 $x_{cp}$ 为例，线性模型假设 $y = b + w·x_{cp}$ ，所以 $w$ 和 $b$ 可以猜测很多模型：
$$
f_1: y = 10.0 + 9.0·x_{cp} \\
f_2: y = 9.8 + 9.2·x_{cp} \\
f_3: y = - 0.8 - 1.2·x_{cp} \\
···
$$

虽然可以做出很多假设，但在这个例子中，显然 $f_3: y = - 0.8 - 1.2·x_{cp}$ 的假设是不合理的，不能进化后CP值是个负值吧~~

#### 多元线性模型（多个特征）
在实际应用中，输入特征肯定不止 $x_{cp}$ 这一个。例如，进化前的CP值、物种（Bulbasaur）、血量（HP）、重量（Weight）、高度（Height）等，特征会有很多。

所以我们假设 **线性模型 Linear model**：$y = b + \sum w_ix_i$
- $x_i$：就是各种特征(fetrure)  $x_{cp},x_{hp},x_w,x_h,···$	
- $w_i$：各个特征的权重 $w_{cp},w_{hp},w_w,w_h,··$
- $b$：偏移量

注意：接下来的内容需要看清楚是【单个特征】还是【多个特征】的示例

## 45
### Step 2：模型评估 - 损失函数
【单个特征】: $x_{cp}$

#### 收集和查看训练数据
这里定义 $x^1$ 是进化前的CP值，$\hat{y}^1$ 进化后的CP值，$\hat{}$ 所代表的是真实值

## 46

将10组原始数据在二维图中展示，图中的每一个点 $(x_{cp}^n,\hat{y}^n)$ 对应着 进化前的CP值 和 进化后的CP值。

## 47

有了这些真实的数据，那我们怎么衡量模型的好坏呢？从数学的角度来讲，我们使用距离。求【进化后的CP值】与【模型预测的CP值】差，来判定模型的好坏。也就是使用损失函数（Loss function） 来衡量模型的好坏，统计10组原始数据 $\left ( \hat{y}^n - f(x_{cp}^n) \right )^2$ 的和，和越小模型越好。


如果觉得看着这个图会晕，忽略图4，直接看公式推导的过程：

$$
\begin{aligned}  
L(f) & = \sum_{n=1}^{10}\left ( \hat{y}^n - f(x_{cp}^n) \right )^2，将【f(x) = y】, 【y= b + w·x_{cp}】代入 \\
& = \sum_{n=1}^{10}\left ( \hat{y}^n - (b + w·x_{cp}) \right )^2\\
\end{aligned} 
$$

最终定义 损失函数 Loss function：$L(w,b)= \sum_{n=1}^{10}\left ( \hat{y}^n - (b + w·x_{cp}) \right )^2$

## 48

我们将 $w$, $b$ 在二维坐标图中展示

- 图中每一个点代表着一个模型对应的 $w$ 和 $b$
- 颜色越深代表模型更优

可以与后面的图11（等高线）进行对比

## 49

### Step 3：最佳模型 - 梯度下降

【单个特征】: $x_{cp}$

#### 如何筛选最优的模型（参数w，b）
已知损失函数是 $L(w,b)= \sum_{n=1}^{10}\left ( \hat{y}^n - (b + w·x_{cp}) \right )^2$ ，需要找到一个令结果最小的 $f^*$，在实际的场景中，我们遇到的参数肯定不止 $w$, $b$。

## 50

先从最简单的只有一个参数$w$入手，定义$w^* = arg\ \underset{x}{\operatorname{\min}} L(w)$

## 51

首先在这里引入一个概念 学习率 ：移动的步长，如图7中 $\eta$

- 步骤1：随机选取一个 $w^0$
- 步骤2：计算微分，也就是当前的斜率，根据斜率来判定移动的方向
	- 大于0向右移动（增加$w$）
	- 小于0向左移动（减少$w$）
- 步骤3：根据学习率移动
- 重复步骤2和步骤3，直到找到最低点

## 52

步骤1中，我们随机选取一个 $w^0$，如图8所示，我们有可能会找到当前的最小值，并不是全局的最小值，这里我们保留这个疑问，后面解决。

## 53

解释完单个模型参数$w$，引入2个模型参数 $w$ 和 $b$ ， 其实过程是类似的，需要做的是偏微分，过程如图9所示，偏微分的求解结果文章后面会有解释，详细的求解过程自行Google。

整理成一个更简洁的公式：右上角所示

## 54
#### 梯度下降推演最优模型的过程

如果把 $w$ 和 $b$ 在图形中展示：

- 每一条线围成的圈就是等高线，代表损失函数的值，颜色约深的区域代表的损失函数越小
- 红色的箭头代表等高线的法线方向

## 55
#### 梯度下降算法在现实世界中面临的挑战

我们通过梯度下降gradient descent不断更新损失函数的结果，这个结果会越来越小，那这种方法找到的结果是否都是正确的呢？前面提到的当前最优问题外，还有没有其他存在的问题呢？

## 56

其实还会有其他的问题：
- 问题1：当前最优（Stuck at local minima）
- 问题2：等于0（Stuck at saddle point）
- 问题3：趋近于0（Very slow at the plateau）

注意：其实在线性模型里面都是一个碗的形状（山谷形状），梯度下降基本上都能找到最优点，但是再其他更复杂的模型里面，就会遇到 问题2 和 问题3 了

## 57-58
w和b偏微分的计算方法

## 59
#### 如何验证训练好的模型的好坏
使用训练集和测试集的平均误差来验证模型的好坏
我们使用将10组原始数据，训练集求得平均误差为31.9，如图所示：

## 60

然后再使用10组Pokemons测试模型，测试集求得平均误差为35.0 如图所示：

## 61
#### 更强大复杂的模型：1元N次线性模型

在模型上，我们还可以进一部优化，选择更复杂的模型，使用1元2次方程举例，如图17，发现训练集求得平均误差为15.4，测试集的平均误差为18.4

这里我们又提出一个新的问题：是不是能画出直线就是线性模型，各种复杂的曲线就是非线性模型？
其实还是线性模型，因为把 $x_{cp}^1$ = $(x_{cp})^2$ 看作一个特征，那么 $y = b + w_1·x_{cp} + w_2·x_{cp}^1$ 其实就是线性模型。

## 62-64
#### 过拟合问题出现
在模型上，我们再可以进一部优化，使用更给次方的模型，如图所示
- 训练集平均误差【15.4】【15.3】【14.9】【12.8】
- 测试集平均误差【18.4】【18.1】【28.8】【232.1】

在训练集上面表现更为优秀的模型，为什么在测试集上效果反而变差了？这就是模型在训练集上过拟合的问题。

## 65
如图所示，每一个模型结果都是一个集合，$5次模型包 \supseteq  4次模型 \supseteq  3次模型$
所以在4次模型里面找到的最佳模型，肯定不会比5次模型里面找到更差

## 66

将错误率结果图形化展示，发现3次方以上的模型，已经出现了过拟合的现象：

## 67
#### 步骤优化

输入更多Pokemons数据，相同的起始CP值，但进化后的CP差距竟然是2倍。

## 68
其实将Pokemons种类通过颜色区分，就会发现Pokemons种类是隐藏得比较深得特征，不同Pokemons种类影响了进化后的CP值的结果。

## 69-71
#### Step1优化：2个input的四个线性模型是合并到一个线性模型中

通过对 Pokemons种类 判断，将 4个线性模型 合并到一个线性模型中

## 72
#### Step2优化：如果希望模型更强大表现更好（更多参数，更多input）


在最开始我们有很多特征，图形化分析特征，将血量（HP）、重量（Weight）、高度（Height）也加入到模型中

## 73
更多特征，更多input，数据量没有明显增加，仍旧导致overfitting

## 74
#### Step3优化：加入正则化

更多特征，但是权重 $w$ 可能会使某些特征权值过高，仍旧导致overfitting，所以加入正则化

- $w$ 越小，表示 $function$ 较平滑的， $function$输出值与输入值相差不大 
- 在很多应用场景中，并不是 $w$ 越小模型越平滑越好，但是经验值告诉我们 $w$ 越小大部分情况下都是好的。
- $b$ 的值接近于0 ，对曲线平滑是没有影响

## 75
如图

## 76

- **Pokemon**：原始的CP值极大程度的决定了进化后的CP值，但可能还有其他的一些因素。
- **Gradient descent**：梯度下降的做法；但是它的理论依据和要点需要同学们自己去学习。
- **Overfitting和Regularization**：过拟合和正则化，主要介绍了表象；后面同学们自己学习更多这方面的理论


# Section 3 Deep Learning
## 80
#### 深度学习的发展趋势
回顾一下deep learning的历史：
感知机（Perceptron）非常像我们的逻辑回归（Logistics Regression）只不过是没有`sigmoid`激活函数。09年的GPU的发展是很关键的，使用GPU矩阵运算节省了很多的时间。

## 81
#### 深度学习的三个步骤
我们都知道机器学习有三个step，对于deep learning其实也是3个步骤：

- Step1：神经网络（Neural network）
- Step2：模型评估（Goodness of function）
- Step3：选择最优函数（Pick best function）

那对于深度学习的Step1就是神经网络（Neural Network）

## 82
#### Step1：神经网络
神经网络（Neural network）里面的节点，类似我们的神经元。

神经网络也可以有很多不同的连接方式，这样就会产生不同的结构（structure）在这个神经网络里面，我们有很多逻辑回归函数，其中每个逻辑回归都有自己的权重和自己的偏差，这些权重和偏差就是参数。
那这些神经元都是通过什么方式连接的呢？其实连接方式都是你手动去设计的。

## 83
#### 完全连接前馈神经网络
概念：前馈（feedforward）也可以称为前向，从信号流向来理解就是输入信号进入网络后，信号流动是单向的，即信号从前一层流向后一层，一直到输出层，其中任意两层之间的连接并没有反馈（feedback），亦即信号没有从后一层又返回到前一层。

- 当已知权重和偏差时输入$(1,-1)​$的结果
- 当已知权重和偏差时输入$(-1,0)$的结果

## 84
上图是输入为1和-1的时候经过一系列复杂的运算得到的结果

## 85
当输入0和0时，则得到0.51和0.85，所以一个神经网络如果权重和偏差都知道的话就可以看成一个函数，他的输入是一个向量，对应的输出也是一个向量。不论是做回归模型（linear model）还是逻辑回归（logistics regression）都是定义了一个函数集（function set）。我们可以给上面的结构的参数设置为不同的数，就是不同的函数（function）。这些可能的函数（function）结合起来就是一个函数集（function set）。这个时候你的函数集（function set）是比较大的，是以前的回归模型（linear model）等没有办法包含的函数（function），所以说深度学习（Deep Learning）能表达出以前所不能表达的情况。

## 86
我们通过另一种方式显示这个函数集：
##### 全链接和前馈的理解
- 输入层（Input Layer）：1层
- 隐藏层（Hidden Layer）：N层
- 输出层（Output Layer）：1层

- 为什么叫全链接呢？
	- 因为layer1与layer2之间两两都有连接，所以叫做Fully Connect；
- 为什么叫前馈呢？
	- 因为现在传递的方向是由后往前传，所以叫做Feedforward。

## 87-88
##### 深度的理解
那什么叫做Deep呢？Deep = Many hidden layer。那到底可以有几层呢？这个就很难说了，以下是一些比较深的神经网络的例子

- 2012 AlexNet：8层
- 2014 VGG：19层
- 2014 GoogleNet：22层
- 2015 Residual Net：152层

随着层数变多，错误率降低，随之运算量增大，通常都是超过亿万级的计算。对于这样复杂的结构，我们一定不会一个一个的计算，对于亿万级的计算，使用loop循环效率很低。

## 89
这里我们就引入矩阵计算（Matrix Operation）能使得我们的运算的速度以及效率高很多：

#### 矩阵计算
如下图所示，输入是 $$\begin{bmatrix}&1&-2\\ &-1&1\end{bmatrix}$$，输出是$$\begin{bmatrix}&0.98\\ &0.12\end{bmatrix}$$。
计算方法就是：sigmoid（权重w【黄色】 * 输入【蓝色】+ 偏移量b【绿色】）= 输出

其中sigmoid更一般的来说是激活函数(activation function)，现在已经很少用sigmoid来当做激活函数。

## 90
如果有很多层呢？
$$a^1 = \sigma (w^1x+b^1) \\
a^2 = \sigma (w^1a^1+b^2) \\ 
··· \\ 
y = \sigma (w^La^{L-1}+b^L) ​$$

## 91
计算方法就像是嵌套，这里就不列公式了，结合上一个图更好理解。所以整个神经网络运算就相当于一连串的矩阵运算。

从结构上看每一层的计算都是一样的，也就是用计算机进行并行矩阵运算。
这样写成矩阵运算的好处是，你可以使用GPU加速。
整个神经网络可以这样看

## 92
#### 本质：通过隐藏层进行特征转换
把隐藏层通过特征提取来替代原来的特征工程，这样在最后一个隐藏层输出的就是一组新的特征（相当于黑箱操作）而对于输出层，其实是把前面的隐藏层的输出当做输入（经过特征提取得到的一组最好的特征）然后通过一个多分类器（可以是softmax函数）得到最后的输出y。

## 93
#### 示例：手写数字识别
举一个手写数字体识别的例子：
输入：一个16*16=256维的向量，每个pixel对应一个dimension，有颜色用（ink）用1表示，没有颜色（no ink）用0表示
输出：10个维度，每个维度代表一个数字的置信度。

从输出结果来看，每一个维度对应输出一个数字，是数字2的概率为0.7的概率最大。说明这张图片是2的可能性就是最大的

## 94

在这个问题中，唯一需要的就是一个函数，输入是256维的向量，输出是10维的向量，我们所需要求的函数就是神经网络这个函数

## 95
从上图看神经网络的结构决定了函数集（function set），所以说网络结构（network structured）很关键。

## 96

接下来有几个问题：
- 多少层？ 每层有多少神经元？
这个问我们需要用尝试加上直觉的方法来进行调试。对于有些机器学习相关的问题，我们一般用特征工程来提取特征，但是对于深度学习，我们只需要设计神经网络模型来进行就可以了。对于语音识别和图像识别，深度学习是个好的方法，因为特征工程提取特征并不容易。
- 结构可以自动确定吗？
有很多设计方法可以让机器自动找到神经网络的结构的，比如进化人工神经网络（Evolutionary Artificial Neural Networks）但是这些方法并不是很普及 。
- 我们可以设计网络结构吗？
可以的，比如 CNN卷积神经网络（Convolutional Neural Network ）

## 97
### Step2: 模型评估

## 98
#### 损失示例

对于模型的评估，我们一般采用损失函数来反应模型的好差，所以对于神经网络来说，我们采用交叉熵（cross entropy）函数来对$y$和$\hat{y}​$的损失进行计算，接下来我们就是调整参数，让交叉熵越小越好。

## 99
#### 总体损失

对于损失，我们不单单要计算一笔数据的，而是要计算整体所有训练数据的损失，然后把所有的训练数据的损失都加起来，得到一个总体损失L。接下来就是在function set里面找到一组函数能最小化这个总体损失L，或者是找一组神经网络的参数$\theta$，来最小化总体损失L

## 100
### Step3：选择最优函数

## 101
如何找到最优的函数和最好的一组参数呢，我们用的就是梯度下降，这个之前我们已经简单的讲过了。

## 102

具体流程：$\theta$是一组包含权重和偏差的参数集合，随机找一个初试值，接下来计算一下每个参数对应偏微分，得到的一个偏微分的集合$\nabla{L}$就是梯度,有了这些偏微分，我们就可以不断更新梯度得到新的参数，这样不断反复进行，就能得到一组最好的参数使得损失函数的值最小

## 103
自己讲

## 104
#### 反向传播

在神经网络中计算损失最好的方法就是反向传播，我们可以用很多框架来进行计算损失，比如说TensorFlow，theano，Pytorch等等

## 105
深度学习的三个步骤


## 106
为什么要用deep learning

## 107
####  问题1：越深越好？
learning从一层到七层，error rate在不断的下降。能看出network越深，参数越多，performance较也越好。

## 108
#### 问题2：矮胖结构 v.s. 高瘦结构
**真正比较deep和shallow**

比较shallow model较好还是deep model较好，在比较的时候一个前提就是调整shallow和Deep让他们的参数是一样多，这样就会得到一个矮胖的模型和高瘦的模型。

## 109

这个实验的后半段的实验结果是：我们用5层hidden layer，每层2000个neural，得到的error rate是17.2%（error rate是越小越好的）而用相对应的一层的模型，得到的错误率是22.5%，这两个都是对应的拥有相似参数个数的模型。继续看下面的4634个参数和16k个参数，如果你只是单纯的增加parameters，是让network变宽不是变高的话，其实对performance的帮助是比较小的。

所以如果把network变高对performance是很有帮助的，network变宽对performance帮助没有那么好的


## 110
## 引入模块化

问题1：为什么变高比变宽好呢？

我们在做deep learning的时候，其实我们是在模块化这件事。我们在main function时，我们会写一些sub function,一层一层结构化的架构。有一些function是可以共用的，就像一个模型，需要时候去用它减小复杂度(如图所示)

## 111

在 machine learning上，可以想象有这样的test。我们现在要做图像分类，我们把image分为四类(每个类别都有一些data)，然后去train 四个classifier。但问题是boys with long hair的data较少(没有太多的training data)，所以这个boys with long hair的classifier就比较weak(performance比较差)

## 112
解决方法：利用模组化的概念(modularization)的思想

假设我们先不去解那个问题，而是把原来的问题切成比较小的问题。比如说，我们先classifier，这些classifier的工作就是决定有没有一种特征出现。
现在就是不直接去分类长头发男生还是短头发男生，而是我们先输入一张图片，判断是男生还是女生和是长头发还是短头发，虽然说长头发的男生很少，但通过女生的数据和男生的数据都很多，虽然长头发的数据很少，但是短发的人和长发的人的数据都很多。所以，这样训练这些基分类器就不会训练的太差(有足够的数据去训练)

## 113

现在我们要解决真正问题的时候，你的每个分类器就可以去参考输出的基本特征，最后要下决定的分类器，它是把前面的基分类器当做模组，每一个分类器都共用同一组模型(只是用不同的方式来使用它而已)。对分类器来说，它看到前面的基分类器告诉它说是长头发是女生，这个分类器的输出就是yes，反之就是no。

所以他们可以对后面的classifier来说就可以利用前面的classifier(中间)，所以它就可以用比较少的训练数据就可以把结果训练好。

## 114
#### 深度学习

问题2：深度学习和模组化有什么关系？

每一层neural可以被看做是一个basic classifier，第一层的neural就是最基分类器，第二层的neural是比较复杂的classifier，把第一层basic classifier 的output当做第二层的input(把第一层的classifier当做module)，第三层把第二层当做module，以此类推。

在做deep learning的时候，如何做模组化这件事，是机器自动学到的。

做modularization这件事，把我们的模型变简单了(把本来复杂的问题变得简单了)，把问题变得简单了，就算训练数据没有那么多，我们也就可以把这个做好

## 115
自己讲

## 116
#### 普遍性定理

过去有一个理论告诉我们说，任何continuous function，它都可以用一层neural network来完成(只要那一层只要够宽的话)。这是90年代，很多人放弃做deep learning的原因，只要一层hidden layer就可以完成所有的function(一层hidden layer就可以做所有的function)，那做deep learning的意义何在呢？，所以很多人说做deep是很没有必要的，我们只要一个hidden layer就好了。

但是这个理论没有告诉我们的是，它只告诉我们可能性，但是它没有告诉我们说要做到这件事情到底有多有效率。没错，你只要有够多的参数，hidden layer够宽，你就可以描述任何的function。但是这个理论没有告诉我们的是，当我们用这一件事(我们只用一个hidde layer来描述function的时候)它其实是没有效率的。当你有more layer(high structure)你用这种方式来描述你的function的时候，它是比较有效率的。

## 117

### 使用逻辑电路举例

逻辑电路(logistic circuits)跟neural network可以类比。在逻辑电路里面是有一堆逻辑闸所构成的，在neural network里面，neural是有一堆神经元所构成的。若你有修过逻辑电路的话，你会说其实只要两层逻辑门你就可以表示任何的Boolean function，因为逻辑门只要根据input的0、1状态和对应的output分别建立起门电路关系即可建立两级电路

那有一个hidden layer的neural network(一个neural network其实是两层，input，output)可以表示任何的continuous function。


虽然我们用两层逻辑门就描述任何的Boolean function，但实际上你在做电路设计的时候，你根本不可能会这样做。当你不是用两层逻辑门而是用很多层的时候，你拿来设计的电路是比较有效率的(虽然两层逻辑门可以做到同样的事情，但是这样是没有效率的)。若如果类比到neural network的话，其实是一样的，你用一个hidden layer可以做到任何事情，但是用多个hidden layer是比较有效率的。你用多层的neural network，你就可以用比较少的neural就完成同样的function，所以你就会需要比较少的参数，比较少的参数意味着不容易overfitting或者你其实是需要比较少的data，完成你现在要train的任务。(很多人的认知是deep learning就是很多data硬碾压过去，其实不是这样子的，当我们用deep learning的时候，其实我们可以用比较时少的data就可以达到同样的任务)

## 118

### 使用剪窗花举例

一个日常生活中的例子，这个例子是剪窗花(折起来才去剪，而不是真的去把这个形状的花样去剪出来，这样就太麻烦了)，这个跟deep learning有什么关系呢？

## 119
我们用之前讲的例子来做比喻，假设我们现在input的点有四个(红色的点是一类，蓝色的点是一类)。我们之前说，如果你没有hidden layer的话，如果你是linear model，你怎么做都没有办法把蓝色的点和红色的点分来开，当你加上hidden layer会发生怎样的事呢？当你加hidde layeer的时候，你就做了features transformation。你把原来的$x_1$,$x_2$转换到另外一个平面$x_1$plane,$x_2$plane(蓝色的两个点是重合在一起的，如右图所示)，当你从左下角的图通过hidden layer变到右下角图的时候，其实你就好像把原来这个平面对折了一样，所以两个蓝色的点重合在了一起。这就好像是说剪窗花的时候对折一样，如果你在图上戳一个洞，那么当你展开的时候，它在这些地方都会有一些洞(看你对折几叠)。如果你把剪窗花的事情想成training。假设我们已经把这个已经折起来的时候，这时候training data只要告诉我们说，在这个范围之内(有斜线)是positive，在这个区间(无斜线)展开之后就是复杂的图样。training data告诉我们比较简单的东西，但是现在有因为对折的关系，展开以后你就可以有复杂的图案(或者说你在这上面戳个洞，在就等同于在其他地方戳了个洞)。

所以从这个例子来看，一个data，就可以发挥多个data效果。所以，你在做deep learning的时候，你其实是在用比较有效率的方式来使用你的data。你可能很想说真的是这样子吗？下面有一个例子。

## 120
### 使用二位坐标举例

我们有一个function，它的input是二维$R^2$(坐标)，它的output是{0，1}，这个function是一个地毯形式的function(红色菱形的output就要是1，蓝色菱形output就要是0)。那现在我们要考虑如果我们用了不同量的training example在1个hidden layer跟3个hidden layer的时候。我们看到了什么的情形，这边要注意的是，我们要特别调整一个hidden layer和3个hidden layer的参数 (这1个neural network是一个很胖的neural network，3个hidden layer是一个很瘦的neural network，他们的参数是要调整到接近的)

那现在这边是要有10万个data的时候，这两个neural都可以learn出这样的train data(从这个train data sample 10万个data然后去给它学，它学出来就是右边这样的)

那现在我们减小参数的量，减少到只用2万个来做train，这时候你会发现说，你用一个hidden lyaer的时候你的结果的就崩掉了，但如果是3个hidden layer的时候，你的结果变得只是比较差(比train data多的时候要差)，但是你会发现说你用3个hidden layer的时候是有次序的崩坏。这个结果(最右下角)就像是你今天要剪窗花的时候，折起来最后剪坏了，展开以后成这个样子。你会发现说在使用比较少的train data的时候，你有比较多的hidden layer最后得到的结果其实是比较好的。

## 121
#### 端到端的学习

当我们用deep learning的时候，另外的一个好处是我们可以做End-to-end learning。

所谓的End-to-end learning的意思是这样，有时候我们要处理的问题是非常的复杂，比如说语音识别就是一个非常复杂的问题。那么说我们要解一个machine problem我们要做的事情就是，先把一个Hypothesis funuctions(也就是找一个model)，当你要处理1的问题是很复杂的时候，你这个model里面它会是需要是一个生产线(由许多简单的function串接在一起)。比如说，你要做语音识别，你要把语音送进来再到通过一层一层的转化，最后变成文字。当你多End-to-end learning的时候，意思就是说你只给你的model input跟output，你不告诉它说中间每一个function要咋样分工(只给input跟output，让它自己去学)，让它自己去学中间每一个function(生产线的每一个点)应该要做什么事情。

那在deep learning里面要做这件事的时候，你就是叠一个很深的neural network，每一层就是生产线的每一个点(每一层就会学到说自己要做什么样的事情)


## 122
#### 语音识别

比如说，在语音识别里面。还没有用deep learning的时候，我们怎么来做语音识别呢，我们可能是这样做的。

先有一段声音讯号(要把声音对应成文字),你要先做DFT，你不知道这是什么也没有关系，反正就是一个function，变成spectogram，这个spectogram通过filter bank(不知道filter bank是什么，没有关系，就是生产线的另外一个点)，最后得到output，然后再去log(取log是非常有道理的)，然后做DCT得到MFCC,把MFCC丢到GMM里面，最后你得到语音识别的结果。

只有最后蓝色的这个bank是用训练数据学出来的，前面这些绿色的这些都是人手工构造的(研究人的生理定出了这些function)。但是后来有了deep learning以后，这些东西可以用neural network把它取代掉。你就把你的deep network多加几层就可以把DCT拿掉。现在你可以从spectogram开始做，你这这些都拿掉，通通都拿deep neural network取代掉，也可以得到更好的结果。deep learning它要做的事情，你会发现他会自动学到要做filter bank(模拟人类听觉器官所制定的filter)这件事情

## 123
接下来就有人挑战说我们可不可以叠一个很深很深的neural network，直接input就是target main声音讯号，output直接就是文字，中间完全就不用做，那就不需要学信号与系统

Google 有一篇paper是这样子，它最后的结果是这样子的，它拼死去learn了一个很大neural network，input就是声音讯号，完全不做其它的任何事情，它最后可以做到跟有Fourier transform的事情打平，也仅次于打平而已。我目前还没看到input一个声音讯号，比Fourier transform结果比这要好的。

## 124
#### 图像识别
刚刚都是讲语音的例子，图像也是差不多的。大家也都知道，过去图像也是叠很多很多的graph在最后一层用比较简单的classifier

## 125
那现在用一个很深的neural，input直接是piexel，output里面是图像是什么

## 126
#### 更复杂的任务

那deep learning还有什么好处呢。通常我们在意的task是非常复杂的，在这非常复杂的task里面，有非常像的input，会有很不同的output。举例来说，在做影视识别的时候，白色的狗跟北极熊看起来很像，但是你的machine左边要output dog，右边要output bear。有时候很不一样的东西，其实是一样的，横着看火车和侧面看火车，他们其实是不一样，但是output告诉我说一样的。

今天的neural只有一层的话(简单的transform)，你没有办法把一样的东西变成很不一样，把不一样的东西变的很像，原来input很像的东西结果看起来很不像，你要做很多层次的转换。

## 127
举例来说，看这个例子(这个是语言的例子)。在这个图上，把MFCC(语音特征提取)投影到二维上，不同颜色代表的是不同的人说的话。在语音上你会发现说，同样的句子，不同人的说，它的声音讯号，看起来是不一样的(这个红色看起来跟蓝色看起来没关系，蓝色跟绿色没有关系)。有人看这个图，语音识别不能做呀。不同的人说话太不一样了。

如果你今天learn 一个neural network，如果你只要第一层的hidden layer的output，你会发现说，不同的人讲的同样的句子还是很不一样的。

## 128
但是你看第8个hidden layer output的时候， 你会发现说，不同的人说着同样的句子，它自动的被line在一起了，也就是说这个DNN在经过很多hidden layer转换的时候，它把本来看起来很不像的东西，它知道应该是一样的(map在一起了)。在右边的这个图上，你会看到一条一条的线，在这些线中你会看到不同颜色的声音讯号。也就是说不同的人说着同样的话经过8个hidden layer的转换以后，对neural network来说，它就变得很像。

## 129
手写数字识别的例子，input feature是左上角这张图(28*28 pixel，把28 *28pixel project到二维平面的话就是左上角的图)，在这张图上，4跟9几乎是叠在一起的(4跟9很像，几乎没有办法把它分开)。但是我们看hidden layer的output，这时候4跟9还是很像(离的很近)，我们看第2个hidden layer的output(4,7,9)逐渐被分开了，到第三个hidden layer，他们会被分的更开。所以你今天要原来很像的input 最后要分的很开，那你就需要好多hidden layer才能办到这件事情


# Section 4 Keras Example
## 132
#### keras 是什么
Keras 是一个用 Python 编写的高级神经网络 API，它能够以 TensorFlow, CNTK, 或者 Theano 作为后端运行。

## 133
文档链接等

## 134
心得

## 135
#### 示例
以手写数字识别为例

## 136
#### 步骤1：定义模型
neural network是长什么样的，在keras首先定义model是sequential
```python
model = sequential()
```

- 第1个隐藏层
	- 你看要你的neural长什么样子，自己就决定长什么样子，举例，这里hidden layer 有两个layer，每个layer都有500 Neural。已经定义了一个model，然后model.add，加一个Fully connect laye(这里用Dense表示)，然后input，output
	- 然后增加一个activation(激活函数)，将sigmoid当做activation(也可以使用其他的当做activation)
```
model.add(activation('sigmoid'))
```
- 第2个隐藏层
	- 这个layer的input就是上一个layer的output，不用说input是500Neural，keras自己知道

- 输出层：
	- output为10dimension
	- activation为softmax


## 137
#### 步骤2：模型评估

- 评估模型的好坏

compile 编译
```python
model.compile()
```
定义一个loss是什么(不同的场合，需要不同的loss function)
```python
loss = ('cateqorical crossentropy')  #损失函数
```
```python
optimizer #优化器
```
```python
metrics #指标
```

## 138
#### 步骤3：最佳模型

#### 3.1 Configuration

```python
model.compile = (loss = 'categorical crossentropy', optimizer = 'adam')
```
- optimizer后面可以跟不同的方式，这些方式都是梯度下降，只是用的learning rate不同，有一些machine会自己决定learning rate


#### 3.2 寻找最优网络参数

- 给定四个输入, x_train, y_train, batch_size, nb_epoch

## 139
- 训练数据就是一张一张的图片, 每张图片对应的标签就是数字
- Two dimension matrix(X_train)，第一个dimension代表你有多少个example，第二个dimension代表你有多少个pixel
- Two dimension matrix(y_train)，第一个dimension代表你有多少个training example，第二个dimension代表label(黑色的为数字，从0开始计数)

## 140
##### mini-batch 的原理详解
keras model参数`batch_size`和`nb_epoch`

我们在做梯度下降和深度学习时，我们并不是真的最小化总损失,我们会把训练数据随机分成几个mini-batch。
具体步骤：
- 随机初始化神经网络的参数 (跟梯度下降一样)
- 先随机选择第一个batch出来,对选择出来的batch里面total loss, 计算偏微分，根据${L}'$去更新参数
- 然后随机选择第二个batch ，对第二个选择出来的batch里面total loss 计算偏微分，根据${L}''$更新参数
- 反复上述过程，直到把所有的batch都统统过一次，一个epoch才算结束。
注意：假设今天有100个batch的话，就把这个参数更新100次，把所有的batch都遍历过叫做一个epoch。

## 141
```
 model.fit(x_train, y_train, batch_size =100, nb_epoch = 20)
```
1. 这里的batch_size代表一个batch有多大(就是把100个example，放到一个batch里)
2. nb_epoch等于20表示对每个batch重复20次

## 142
##### 使用mini-batch的原因：Speed

- batch-szie不同时，一个epoch所需的时间是不一样的（上图用batch size=1是166s，当batch size=10是17s）
- batch =10相比于batch=1，较稳定

## 143
- Speed-- why minni batch is faster than stochastic GD(为什么批量梯度下降比随机梯度下降要快)
  因为利用计算机的平行运算，之前也提到过矩阵运算会使计算速度快很多。
- 很大的batch size会导致很差的表现（不能设置太大也不能设置太小）

## 144

用随机梯度下降的时候两个矩阵x是分开计算的，当用mini batch的时候，直接是用两个x合并在一起，一起计算得到$Z^1$和$Z^2$，对GPU来说上面运算时间是下面运算时间的两倍，这就是为什么我们用上mini batch和GPU的时候速度会加快的原理。但是如果你用了GPU没用mini batch的话，那也达不到加速的效果。

## 145
### 模型保存和使用

```python
#case1：测试集正确率
score = model.evaluate(x_test,y_test)
print("Total loss on Testing Set:", score[0])
print("Accuracy of Testing Set:", score[1])

#case2：模型预测
result = model。predict(x_test)
```

## 146
使用GPU加速

## 148
#### 机器学习的下一步
假设我们要把机器学习更多应用到生活中，还有哪些问题是需要我们克服的

## 149
#### 机器能不能知道“我不知道”
这是一个很形而上的问题，你知道你不知道这样。机器能不能知道这件事情呢？很多时候，你可能训练一个动物识别器，机器知道这是一只猫，正确率可能非常高，真正上线后，输入不仅仅会是一只猫，可能输入一个人图像，这个时候，机器是把这个人硬塞进某一种动物，还是说你的机器有能力知道这个是我不知道的东西。机器会回答这是我不知道的，这样的技术就是Anomaly Detection (异常检测)。

## 150
#### 说出为什么“我知道”

今天我们看到各式各样机器学习非常强大的力量，感觉机器好像非常的聪明，过去有一只马叫做汉斯，它非常的聪明，聪明到甚至可以做数学。举例来说：你跟它讲根号9是多少，它就会敲它的马蹄，大家欢呼道，这是一只会算数学的马。可以解决根号的问题，大家都觉得非常的惊叹。后面就有人怀疑说：难道汉斯真的这么聪明吗？在没有任何的观众的情况下，让汉斯自己去解决一个数学题目，这时候它就会一直踏它的马蹄，一直的不停。这是为什么呢？因为它之前学会了观察旁观人的反应，它知道什么时候该停下来。它可能不知道自己在干什么，它也不知道数学是什么，但是踏对了正确的题目就有萝卜吃，它只是看了旁边人的反应得到了正确的答案。

今天我们看到种种机器学习的成果，难道机器真的有那么的聪明吗？会不会它会汉斯一样用了奇怪的方法来得到答案的。


## 151

这个东西其实是有可能发生的，举例来说，输入一双球鞋，xxx

## 152
有人做了一个马的识别器，两个model的识别率都很高。然后分析，机器是根据什么来标识马的。第一个模型是看到图上黄红部分正常分析出有马，第二个模型是看到下面红色部分，识别出有马，它只是看到左下角的英文，标识出马，并没有学到马。

我们不知道AI有没有那么聪明，我们需要一些技术，让AI不只是做出决定，还要让它告诉我们说它为什么做出这样的决定。

## 153
#### 机器的错觉
我们知道说，人是有错觉的，比如下面两个圈圈，左边的圈圈颜色比较深，但是人有时会有错觉，觉得右边这个圈圈颜色比较深。

机器跟人一样，也很容易被骗，我们可以加一些噪声，让机器本来以为是的后来判断为不是。如本来判断出来是熊喵，加了噪声，就判断错误了。这种就叫做 Adversarial Attack，这个要如何防止呢？即如何防止机器发生错觉~

## 154
#### 终身学习
我们也要机器终生学习。人就是终生学习的，上学期修了线性代数，这学期学机器学习，学好线性代数，机器学习学得更容易。机器能不能跟人一样也做终生学习呢？

## 155
现在我们一般只让一个模型学习一个任务，比如Alpha Go就只学习下围棋，Alpha star就是玩星际争霸，它们并不是同一个模型。

## 156
今天我们只让一个模型学习一个人任务，显然会存在如下问题
- 模型的数量无限增长
- 之前学到的技能对之后的学习没有帮助

为什么我们今天不让机器去终生学习呢？比如我们先让机器学下围棋，然后再让它学星际争霸，那么尴尬了，学完星际争霸之后它就不会下围棋了。这个叫做Catastrophic Forgetting（灾难性遗忘）。如果想让机器做终身学习，还尚在解决的问题

## 157
#### 学习如何学习
过去我们是写一个程序，让机器具有学习的能力，现在我们能不能写一个程序让机器学习具有学习的能力，这个程序能够写出程序让机器具备学习能力，这个技术叫做Meta-Learning 或者 Learn to Learn。学习如何学习，过去我们设定了学习的演算法让机器学习，今天我们能不能让机器自己学习演算法，然后根据这些演算法进行学习。

## 158
#### 一定需要很多训练资料吗？
- Few-shot learning
让机器看少量的数据，去学会
- Zero-shot learning
不给机器任何资料，只告诉机器物品的特征描述，然后机器根据描述进行判断。

## 159
#### 强化学习
Reinforcement Learning 真的有这么强吗？当你用Reinforcement Learning 去打一些电子游戏，Reinforcement Learning也许确实可以跟人做到差不多，但是需要很长时间才能达到，如下图机器需要900多个小时才能达到人类2个小时能达到的效果。机器感觉就是一个天资不佳却勤奋不解的笨小孩，即Reinforcement Learning为什么学得这么慢，有没有办法让它快一点?

## 160
强化学习以reward为激励

## 161

#### 神经网络压缩
假设我们要把机器学习的模型应用到生活当中，device的运算能力有限，内存有限，接下来的问题是我们能不能把Network 架构缩小，让它有同样的能力。首先能不能把一个大的神经网络缩小，减掉多余的神经元；或者能不能把一个神经网络的参数进行二值化，都变成“+1”和“-1”。如果是连续数值，就需要大量的运算和内存，如果把所有参数进行二值化，那么运算起来就快，内存也占用少。

## 162
#### 机器学习的谎言
今天我们在训练的时候，假设训练和测试的数据分布是一样的或者至少非常相似，但是实际上在真实应用里面，这就是一个谎言。

## 163
如果今天你在做手写数字识别，训练资料和测试资料非常相似，可能会很容易达到99.5%。但是实际中，可能图片有背景，正确率变成57.5%，直接烂掉了。那么怎么解决机器在训练资料和测试资料不同的场景呢？现有技术有Unsupervised Domain Adaptation (无监督领域自适应)。


## 164-166
总结


